{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import os\n",
    "from fpdf import FPDF\n",
    "import yake\n",
    "import pytz\n",
    "import glob\n",
    "import shutil\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "\n",
    "def fetch_time():\n",
    "    current_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
    "    format_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    tag_time = str(current_time.day) + str(current_time.month) + str(current_time.year) + str(current_time.hour) + str(current_time.minute) + str(current_time.second)\n",
    "    \n",
    "    return format_time, tag_time\n",
    "\n",
    "def create_pdf(format_time):\n",
    "    #Convert txt to PDF\n",
    "    pdf = FPDF()\n",
    "    # Add a page\n",
    "    pdf.add_page()\n",
    "\n",
    "    # set style and size of font\n",
    "    # that you want in the pdf\n",
    "    pdf.add_font('DejaVu', '', './fonts/Tinos-Regular.ttf', uni=True)\n",
    "    pdf.set_font('DejaVu', '', 14)\n",
    "\n",
    "    #Setting credentials\n",
    "    pdf.set_text_color(0,0,0)  \n",
    "    txt_1=\"FENS Job Market Weekly Feed\"\n",
    "    txt_2=\"Last updated on: \"+str(format_time)+\" IST\"\n",
    "    txt_3=\"github.com/pradhanhitesh\"\n",
    "    pdf.cell(200, 10, txt = txt_1,ln = 1, align = 'C')\n",
    "    pdf.cell(200, 10, txt = txt_2,ln = 2, align = 'C')\n",
    "    pdf.cell(200, 10, txt = txt_3,ln = 2, align = 'C')\n",
    "    pdf.ln(h=6)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "def update_data():\n",
    "    fens_files = glob.glob('./FENS*')\n",
    "    if len(fens_files) > 0:\n",
    "        # print(\"FILES FOUND\")\n",
    "        for i in range(len(fens_files)):\n",
    "            shutil.move(fens_files[i],'./data/')\n",
    "\n",
    "    return\n",
    "\n",
    "def get_metadata(pdf,format_time,tag_time):    \n",
    "    file_name = \"FENS_\" + tag_time + \".txt\"\n",
    "    keywords_dump = []\n",
    "\n",
    "    with open(file_name,'wt') as f :\n",
    "\n",
    "        urls=[\"https://www.fens.org/careers/job-market\"]\n",
    "        for url in urls:\n",
    "            # Send a request to the URL\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            print(f\"{format_time} REQUEST SENT!\")\n",
    "\n",
    "            # Parse the content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            href_tags = soup.find_all(href=True)\n",
    "\n",
    "            job_links=[]\n",
    "            for i in range(len(href_tags)):\n",
    "                fullstring = str(href_tags[i])\n",
    "                substring = \"https://www.fens.org/careers/job-market/job/\"\n",
    "                try:\n",
    "                    fullstring.index(substring)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                else:\n",
    "                    # print(fullstring)\n",
    "                    job_links.append(fullstring)\n",
    "\n",
    "            print(f\"{format_time} JOBS FETCHED!\")\n",
    "\n",
    "            for k in range(10):\n",
    "                if re.sub('<[^<]+?>', '', str(job_links[k])).isdigit():\n",
    "                    url_job=\"https://www.fens.org/careers/job-market/job/\" + re.sub('<[^<]+?>', '', str(job_links[k])) + \"/\"\n",
    "                    print(url_job,file=f)\n",
    "                    pdf.set_text_color(0,0,255) \n",
    "                    pdf.write(4,url_job)\n",
    "                    pdf.ln(h=5)\n",
    "                    \n",
    "                    # Send a request to the URL\n",
    "                    response = requests.get(url_job)\n",
    "                    response.raise_for_status()\n",
    "\n",
    "                    # Parse the content using BeautifulSoup\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                    #Get title\n",
    "                    title_tags = soup.find_all('title')\n",
    "                    title=str(title_tags).split('>')[1].split('<')[0]\n",
    "                    print(\"Title: \",title)\n",
    "                    pdf.set_text_color(0,0,0) \n",
    "                    title_text=\"Title: \"+str(title_tags).split('>')[1].split('<')[0]\n",
    "                    pdf.multi_cell(w=190, h=5, txt=title_text, border=0, align='L', fill=False)\n",
    "\n",
    "                    keywords=['<p>Job ID:','<p><b>Position:','<p><b>Deadline:',\n",
    "                            '<p><b>Employment Start Date:','<p><b>Country:','<p><b>Institution:','URL:',\n",
    "                            \"<p><b>Department:\"]\n",
    "\n",
    "                    for j in range(len(list(soup.find_all('p')))):\n",
    "                        for keys in keywords:\n",
    "                            if str(soup.find_all('p')[j]).find(keys) != -1:\n",
    "                                print(re.sub('<[^<]+?>', '',str(soup.find_all('p')[j])))\n",
    "                                pdf.write(4,re.sub('<[^<]+?>', '',str(soup.find_all('p')[j])))\n",
    "                                pdf.ln(h=5)\n",
    "\n",
    "                    save_des=[\"<p><b>Description:\"]\n",
    "                    for j in range(len(list(soup.find_all('p')))):\n",
    "                        for keys in save_des:\n",
    "                            if str(soup.find_all('p')[j]).find(keys) != -1:\n",
    "                                text_save = re.sub('<[^<]+?>', '',str(soup.find_all('p')[j]))\n",
    "                                kw_extractor = yake.KeywordExtractor(top=10, stopwords=None)\n",
    "                                keywords = kw_extractor.extract_keywords(text_save)\n",
    "                                text=\"Keywords: \"\n",
    "\n",
    "                                for kw in range(len(keywords)):\n",
    "                                    text=text+keywords[kw][0]+\"; \"\n",
    "                                    keywords_dump.append(keywords[kw][0])\n",
    "                                    if kw == 9:\n",
    "                                        print(text)\n",
    "                                        pdf.multi_cell(w=190, h=5, txt=text, border=0, align='L', fill=False)\n",
    "                                        pdf.ln(h=5)\n",
    "    \n",
    "    return pdf.output(\"FENS_\"+tag_time+\".pdf\"),keywords_dump\n",
    "\n",
    "def send_mail(format_time,tag_time):\n",
    "    msg = EmailMessage()\n",
    "    msg[\"From\"] = os.environ.get('FROM_ID')\n",
    "    msg[\"Subject\"] = \"FENS Weekly Update\" \n",
    "    msg[\"To\"] = os.environ.get('TO_ID')\n",
    "    msg.set_content(f\"Dear subscriber, \\nPlease find attached the FENS Weekly Update. \\nGenerated on {format_time} IST. \\n\\nRegards,\\nHitesh Pradhan\")\n",
    "\n",
    "    with open(\"FENS_\"+ tag_time +\".pdf\", 'rb') as content_file:\n",
    "        content = content_file.read()\n",
    "        msg.add_attachment(content, maintype='application', subtype='pdf', filename=\"FENS_\"+ tag_time +\".pdf\")\n",
    "\n",
    "    s = smtplib.SMTP_SSL('smtp.gmail.com')\n",
    "    s.login(os.environ.get('EMAIL'),os.environ.get('LOGIN_KEY')) #Add your credentials\n",
    "    s.send_message(msg)\n",
    "\n",
    "    return\n",
    "\n",
    "def generate_html(format_time):\n",
    "    template_vars = {\n",
    "        'format_time' : format_time\n",
    "    }\n",
    "\n",
    "    return template_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 15:03:37 REQUEST SENT!\n",
      "2024-01-22 15:03:37 JOBS FETCHED!\n",
      "Title:  PhD Position in electrophysiology of tick neurons - Federation of European Neuroscience Societies\n",
      "Job ID: 117507\n",
      "Position: Ph.D. Student\n",
      "Deadline: 15 March 2024\n",
      "Employment Start Date: 1 October 2024\n",
      "Country: France\n",
      "Institution: University of Orleans (France)/P2E laboratory/ Team : Neurobiology and Neuropharmacology of Ion Channels (NNIC)\n",
      "Department: Biology and Biochemistry\n",
      "URL: https://www.univ-orleans.fr/fr/p2e/equipes/neurobiologie-et-neuropharmacologie-des-canaux-ioniques\n",
      "Keywords: tick Ixodes ricinus; nicotinic acetylcholine receptors; Project title; Pharmacology and intracellular; tick Ixodes; Ixodes ricinus; neuronal nicotinic acetylcholine; Ixodes ricinus neuronal; acetylcholine receptors; nicotinic acetylcholine; \n",
      "Title:  Application Specialist - Federation of European Neuroscience Societies\n",
      "Job ID: 117502\n",
      "Position: Commercial Position\n",
      "Deadline: 16 February 2024\n",
      "Employment Start Date: 4 March 2024\n",
      "Country: Finland\n",
      "Institution: Neurotar Oy Ltd\n",
      "Department: \n",
      "URL: https://www.neurotar.com/\n",
      "Keywords: facilitates high-precision tests; Mobile HomeCage; equipment facilitates high-precision; proprietary Mobile HomeCage; behaving mice; tests in awake; facilitates high-precision; high-precision tests; Neurotar; sales; \n",
      "Title:  Data scientist position in cortical inhibitory microcircuits - Federation of European Neuroscience Societies\n",
      "Job ID: 117478\n",
      "Position: data science engineer position\n",
      "Deadline: 31 December 2024\n",
      "Country: France\n",
      "Institution: Paris Brain Institute\n",
      "Department: \n",
      "URL: https://baccilab.org/\n",
      "Keywords: Paris Brain Institute; Alberto Bacci; laboratory of Alberto; Paris Brain; Brain Institute; Paris; data science engineer; science engineer position; France; Institute; \n",
      "Title:  Postdoctoral Research Associate - Federation of European Neuroscience Societies\n",
      "Job ID: 117475\n",
      "Position: Post-doctoral Position\n",
      "Deadline: 24 February 2024\n",
      "Country: United States\n",
      "Institution: University of Virginia School of Medicine\n",
      "Department: Department of Pharmacology\n",
      "URL: https://med.virginia.edu/faculty/faculty-listing/jjz4n/\n",
      "Keywords: postdoctoral Research Associate; Department of Pharmacology; Research Associate; Pharmacology is seeking; seeking applications; postdoctoral Research; University of Virginia; multiple patch-clamp recordings; Department; Associate; \n"
     ]
    }
   ],
   "source": [
    "format_time, tag_time = fetch_time()\n",
    "pdf = create_pdf(format_time)\n",
    "\n",
    "update_data()         \n",
    "keywords_dump = get_metadata(pdf,format_time,tag_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
