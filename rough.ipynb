{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import os\n",
    "from fpdf import FPDF\n",
    "import yake\n",
    "import pytz\n",
    "import glob\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetch_time():\n",
    "    current_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
    "    format_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    tag_time = str(current_time.day) + str(current_time.month) + str(current_time.year) + str(current_time.hour) + str(current_time.minute)\n",
    "    \n",
    "    return current_time, format_time, tag_time\n",
    "\n",
    "def _create_pdf(format_time):\n",
    "    #Convert txt to PDF\n",
    "    pdf = FPDF()\n",
    "    # Add a page\n",
    "    pdf.add_page()\n",
    "\n",
    "    # set style and size of font\n",
    "    # that you want in the pdf\n",
    "    pdf.add_font('DejaVu', '', './fonts/Tinos-Regular.ttf', uni=True)\n",
    "    pdf.set_font('DejaVu', '', 14)\n",
    "\n",
    "    #Setting credentials\n",
    "    pdf.set_text_color(0,0,0)  \n",
    "    txt_1=\"FENS Job Market Weekly Feed\"\n",
    "    txt_2=\"Last updated on: \"+str(format_time)+\" IST\"\n",
    "    txt_3=\"github.com/pradhanhitesh\"\n",
    "    pdf.cell(200, 10, txt = txt_1,ln = 1, align = 'C')\n",
    "    pdf.cell(200, 10, txt = txt_2,ln = 2, align = 'C')\n",
    "    pdf.cell(200, 10, txt = txt_3,ln = 2, align = 'C')\n",
    "    pdf.ln(h=6)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "def _move_fens():\n",
    "    fens_files = glob.glob('./FENS*')\n",
    "    if len(fens_files) > 0:\n",
    "        # print(\"FILES FOUND\")\n",
    "        for i in range(len(fens_files)):\n",
    "            shutil.move(fens_files[i],'./data/')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_metadata(pdf,format_time,tag_time):    \n",
    "    file_name = \"FENS\" + tag_time + \".txt\"\n",
    "\n",
    "    with open(file_name,'wt') as f :\n",
    "\n",
    "        urls=[\"https://www.fens.org/careers/job-market\"]\n",
    "        for url in urls:\n",
    "            # Send a request to the URL\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            print(f\"{format_time} REQUEST SENT!\")\n",
    "\n",
    "            # Parse the content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            href_tags = soup.find_all(href=True)\n",
    "\n",
    "            job_links=[]\n",
    "            for i in range(len(href_tags)):\n",
    "                fullstring = str(href_tags[i])\n",
    "                substring = \"https://www.fens.org/careers/job-market/job/\"\n",
    "                try:\n",
    "                    fullstring.index(substring)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                else:\n",
    "                    # print(fullstring)\n",
    "                    job_links.append(fullstring)\n",
    "\n",
    "            print(f\"{format_time} JOBS FETCHED!\")\n",
    "\n",
    "            for k in range(2):\n",
    "                if re.sub('<[^<]+?>', '', str(job_links[k])).isdigit():\n",
    "                    url_job=\"https://www.fens.org/careers/job-market/job/\" + re.sub('<[^<]+?>', '', str(job_links[k])) + \"/\"\n",
    "                    print(url_job,file=f)\n",
    "                    pdf.set_text_color(0,0,255) \n",
    "                    pdf.write(4,url_job)\n",
    "                    pdf.ln(h=5)\n",
    "                    \n",
    "                    # Send a request to the URL\n",
    "                    response = requests.get(url_job)\n",
    "                    response.raise_for_status()\n",
    "\n",
    "                    # Parse the content using BeautifulSoup\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                    #Get title\n",
    "                    title_tags = soup.find_all('title')\n",
    "                    title=str(title_tags).split('>')[1].split('<')[0]\n",
    "                    print(\"Title: \",title)\n",
    "                    pdf.set_text_color(0,0,0) \n",
    "                    title_text=\"Title: \"+str(title_tags).split('>')[1].split('<')[0]\n",
    "                    pdf.multi_cell(w=190, h=5, txt=title_text, border=0, align='L', fill=False)\n",
    "\n",
    "                    keywords=['<p>Job ID:','<p><b>Position:','<p><b>Deadline:',\n",
    "                            '<p><b>Employment Start Date:','<p><b>Country:','<p><b>Institution:','URL:',\n",
    "                            \"<p><b>Department:\"]\n",
    "\n",
    "                    for j in range(len(list(soup.find_all('p')))):\n",
    "                        for keys in keywords:\n",
    "                            if str(soup.find_all('p')[j]).find(keys) != -1:\n",
    "                                print(re.sub('<[^<]+?>', '',str(soup.find_all('p')[j])))\n",
    "                                pdf.write(4,re.sub('<[^<]+?>', '',str(soup.find_all('p')[j])))\n",
    "                                pdf.ln(h=5)\n",
    "\n",
    "                    save_des=[\"<p><b>Description:\"]\n",
    "                    for j in range(len(list(soup.find_all('p')))):\n",
    "                        for keys in save_des:\n",
    "                            if str(soup.find_all('p')[j]).find(keys) != -1:\n",
    "                                text_save = re.sub('<[^<]+?>', '',str(soup.find_all('p')[j]))\n",
    "                                kw_extractor = yake.KeywordExtractor(top=10, stopwords=None)\n",
    "                                keywords = kw_extractor.extract_keywords(text_save)\n",
    "                                text=\"Keywords: \"\n",
    "\n",
    "                                for kw in range(len(keywords)):\n",
    "                                    text=text+keywords[kw][0]+\"; \"\n",
    "                                    if kw == 9:\n",
    "                                        print(text)\n",
    "                                        pdf.multi_cell(w=190, h=5, txt=text, border=0, align='L', fill=False)\n",
    "                                        pdf.ln(h=5)\n",
    "    \n",
    "    return pdf.output(\"FENS_\"+tag_time+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 12:50:28 REQUEST SENT!\n",
      "2024-01-22 12:50:28 JOBS FETCHED!\n",
      "Title:  PhD Position in electrophysiology of tick neurons - Federation of European Neuroscience Societies\n",
      "Job ID: 117507\n",
      "Position: Ph.D. Student\n",
      "Deadline: 15 March 2024\n",
      "Employment Start Date: 1 October 2024\n",
      "Country: France\n",
      "Institution: University of Orleans (France)/P2E laboratory/ Team : Neurobiology and Neuropharmacology of Ion Channels (NNIC)\n",
      "Department: Biology and Biochemistry\n",
      "URL: https://www.univ-orleans.fr/fr/p2e/equipes/neurobiologie-et-neuropharmacologie-des-canaux-ioniques\n",
      "Keywords: tick Ixodes ricinus; nicotinic acetylcholine receptors; Project title; Pharmacology and intracellular; tick Ixodes; Ixodes ricinus; neuronal nicotinic acetylcholine; Ixodes ricinus neuronal; acetylcholine receptors; nicotinic acetylcholine; \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ , format_time, tag_time = _fetch_time()\n",
    "pdf = _create_pdf(format_time)\n",
    "\n",
    "_move_fens()         \n",
    "_get_metadata(pdf,format_time,tag_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = EmailMessage()\n",
    "msg[\"From\"] = os.environ.get('FROM_ID')\n",
    "msg[\"Subject\"] = \"FENS Weekly Update\" \n",
    "msg[\"To\"] = os.environ.get('TO_ID')\n",
    "msg.set_content(f\"Dear subscriber, \\nPlease find attached the FENS Weekly Update. \\nGenerated on {format_time} IST. \\n\\nRegards,\\nHitesh Pradhan\")\n",
    "\n",
    "with open(\"FENS_\"+ tag_time +\".pdf\", 'rb') as content_file:\n",
    "    content = content_file.read()\n",
    "    msg.add_attachment(content, maintype='application', subtype='pdf', filename=\"FENS_\"+ tag_time +\".pdf\")\n",
    "\n",
    "s = smtplib.SMTP_SSL('smtp.gmail.com')\n",
    "s.login(os.environ.get('EMAIL'),os.environ.get('LOGIN_KEY')) #Add your credentials\n",
    "s.send_message(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
